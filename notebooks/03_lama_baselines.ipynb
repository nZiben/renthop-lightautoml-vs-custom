{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9518e2",
   "metadata": {},
   "source": [
    "# 03 â€” LAMA baselines (2 configs)\n",
    "\n",
    "Requirements satisfied:\n",
    "- **minimum 2 different LAMA configurations**\n",
    "- choose the best validation score\n",
    "- avoid leakage: we use time-aware holdout split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6377b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from src.config import Paths, TARGET_COL, ID_COL, SEED\n",
    "from src.models.lama import fit_lama_tabular, fit_lama_tabular_nlp\n",
    "from src.utils.seed import set_global_seed\n",
    "\n",
    "set_global_seed(SEED)\n",
    "paths = Paths()\n",
    "\n",
    "df = pd.read_parquet(paths.data_processed/\"model_table.parquet\")\n",
    "spec = json.loads((paths.data_processed/\"feature_spec.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Split back to train/test by presence of target\n",
    "train_df = df[df[TARGET_COL].notna()].copy()\n",
    "test_df  = df[df[TARGET_COL].isna()].copy()\n",
    "\n",
    "# Time-aware holdout: last 20% by created_dt\n",
    "train_df = train_df.sort_values(\"created_dt\")\n",
    "cut = int(len(train_df) * 0.8)\n",
    "tr, va = train_df.iloc[:cut], train_df.iloc[cut:]\n",
    "print(\"train:\", tr.shape, \"valid:\", va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"high\",\"medium\",\"low\"]  # submission column order\n",
    "y_va = va[TARGET_COL].values\n",
    "\n",
    "drop_cols = [ID_COL, TARGET_COL, \"created_dt\"]  # keep only engineered numeric/cat/text cols\n",
    "\n",
    "# --- Config A: TabularAutoML (fast-ish) ---\n",
    "res_a = fit_lama_tabular(\n",
    "    train_df=tr,\n",
    "    valid_df=va,\n",
    "    target_col=TARGET_COL,\n",
    "    drop_cols=drop_cols + spec[\"text_cols\"],  # tabular-only: drop raw text\n",
    "    timeout=600,\n",
    "    cpu_limit=4,\n",
    "    params={\"use_algos\": [[\"lgb\"]]},  # simple, strong baseline\n",
    "    verbose=2,\n",
    ")\n",
    "score_a = log_loss(y_va, res_a.valid_pred, labels=labels)\n",
    "print(\"LAMA Config A logloss:\", score_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config B: TabularAutoML (stronger: more time + more algos) ---\n",
    "res_b = fit_lama_tabular(\n",
    "    train_df=tr,\n",
    "    valid_df=va,\n",
    "    target_col=TARGET_COL,\n",
    "    drop_cols=drop_cols + spec[\"text_cols\"],\n",
    "    timeout=1800,\n",
    "    cpu_limit=4,\n",
    "    params={\"use_algos\": [[\"lgb\", \"linear_l2\"]]},\n",
    "    verbose=2,\n",
    ")\n",
    "score_b = log_loss(y_va, res_b.valid_pred, labels=labels)\n",
    "print(\"LAMA Config B logloss:\", score_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565de9d",
   "metadata": {},
   "source": [
    "## Optional: LAMA with text (TabularNLPAutoML)\n",
    "\n",
    "This may require external model downloads depending on `text_params/autonlp_params`.\n",
    "If you run in a restricted environment, you can skip this section.\n",
    "\n",
    "(If it runs, it's a great second baseline to mention in the report.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NLP = False  # set True if you run on Kaggle / environment with required NLP deps & downloads\n",
    "\n",
    "if RUN_NLP:\n",
    "    res_nlp = fit_lama_tabular_nlp(\n",
    "        train_df=tr,\n",
    "        valid_df=va,\n",
    "        target_col=TARGET_COL,\n",
    "        drop_cols=drop_cols,\n",
    "        text_cols=spec[\"text_cols\"],\n",
    "        timeout=1800,\n",
    "        cpu_limit=4,\n",
    "        params={\"use_algos\": [[\"linear_l2\", \"lgb\"]]},\n",
    "        text_params={\"lang\": \"en\"},\n",
    "        tfidf_params={\"ngram_range\": (1, 2), \"max_features\": 80000},\n",
    "        autonlp_params=None,  # keep TF-IDF only\n",
    "        verbose=2,\n",
    "    )\n",
    "    score_nlp = log_loss(y_va, res_nlp.valid_pred, labels=labels)\n",
    "    print(\"LAMA NLP logloss:\", score_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85823115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n",
    "results = pd.DataFrame(\n",
    "    [\n",
    "        {\"config\": \"TabularAutoML A (lgb, 600s)\", \"logloss\": score_a},\n",
    "        {\"config\": \"TabularAutoML B (lgb+linear, 1800s)\", \"logloss\": score_b},\n",
    "    ]\n",
    ").sort_values(\"logloss\")\n",
    "display(results)\n",
    "\n",
    "ax = results.set_index(\"config\")[\"logloss\"].plot(kind=\"barh\", figsize=(8,3))\n",
    "ax.set_title(\"LAMA baseline comparison (lower is better)\")\n",
    "ax.set_xlabel(\"logloss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09bb82",
   "metadata": {},
   "source": [
    "## Save best LAMA model + create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be022b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = res_a.model if score_a <= score_b else res_b.model\n",
    "best_name = \"lama_a\" if score_a <= score_b else \"lama_b\"\n",
    "\n",
    "# Fit on full train and predict test\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "\n",
    "roles = {\"target\": TARGET_COL, \"drop\": drop_cols + spec[\"text_cols\"]}\n",
    "task = Task(\"multiclass\")\n",
    "\n",
    "automl_full = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=1800,\n",
    "    cpu_limit=4,\n",
    "    general_params={\"use_algos\": [[\"lgb\", \"linear_l2\"]]},\n",
    ")\n",
    "_ = automl_full.fit_predict(train_df, roles=roles, verbose=2)\n",
    "test_pred = automl_full.predict(test_df).data\n",
    "\n",
    "sub = pd.DataFrame({ID_COL: test_df[ID_COL].values})\n",
    "sub[labels] = test_pred\n",
    "\n",
    "out_path = paths.submissions / f\"submission_{best_name}.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(\"Saved submission:\", out_path)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}