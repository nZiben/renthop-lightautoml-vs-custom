{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9518e2",
   "metadata": {},
   "source": [
    "# 03 â€” LAMA baselines (2 configs)\n",
    "\n",
    "Requirements satisfied:\n",
    "- **minimum 2 different LAMA configurations**\n",
    "- choose the best validation score\n",
    "- avoid leakage: we use time-aware holdout split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9f7f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/sergey/code/renthop-lightautoml-vs-custom\n",
      "src exists: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if (PROJECT_ROOT / \"src\").exists() is False and (PROJECT_ROOT.parent / \"src\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"src exists:\", (PROJECT_ROOT / \"src\").exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6377b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (39481, 34) valid: (9871, 34)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from src.config import Paths, TARGET_COL, ID_COL, SEED\n",
    "from src.models.lama import fit_lama_tabular, fit_lama_tabular_nlp\n",
    "from src.utils.seed import set_global_seed\n",
    "\n",
    "set_global_seed(SEED)\n",
    "paths = Paths()\n",
    "\n",
    "df = pd.read_pickle(paths.data_processed/\"model_table.pkl\")\n",
    "spec = json.loads((paths.data_processed/\"feature_spec.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Split back to train/test by presence of target\n",
    "train_df = df[df[TARGET_COL].notna()].copy()\n",
    "test_df  = df[df[TARGET_COL].isna()].copy()\n",
    "\n",
    "# Time-aware holdout: last 20% by created_dt\n",
    "train_df = train_df.sort_values(\"created_dt\")\n",
    "cut = int(len(train_df) * 0.8)\n",
    "tr, va = train_df.iloc[:cut], train_df.iloc[cut:]\n",
    "print(\"train:\", tr.shape, \"valid:\", va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4a7145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:58] Stdout logging level is INFO2.\n",
      "[14:08:58] Task: multiclass\n",
      "\n",
      "[14:08:58] Start automl preset with listed constraints:\n",
      "[14:08:58] - time: 600.00 seconds\n",
      "[14:08:58] - CPU: 4 cores\n",
      "[14:08:58] - memory: 16 GB\n",
      "\n",
      "[14:08:59] \u001b[1mTrain data shape: (39481, 34)\u001b[0m\n",
      "\n",
      "[14:09:02] Layer \u001b[1m1\u001b[0m train process start. Time left 596.45 secs\n",
      "[14:09:13] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[14:09:14] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
      "[14:09:14] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:09:27] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:09:43] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:09:58] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:10:16] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:10:28] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.5907472599567605\u001b[0m\n",
      "[14:10:28] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[14:10:28] Time left 510.12 secs\n",
      "\n",
      "[14:10:28] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[14:10:28] \u001b[1mAutoml preset training completed in 89.89 seconds\u001b[0m\n",
      "\n",
      "[14:10:28] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
      "\n",
      "LAMA Config A logloss: 2.3745999598409773\n"
     ]
    }
   ],
   "source": [
    "labels = [\"high\",\"medium\",\"low\"]  # submission column order\n",
    "y_va = va[TARGET_COL].values\n",
    "\n",
    "drop_cols = [ID_COL, \"created_dt\"]  # keep only engineered numeric/cat/text cols\n",
    "\n",
    "# --- Config A: TabularAutoML (fast-ish) ---\n",
    "res_a = fit_lama_tabular(\n",
    "    train_df=tr,\n",
    "    valid_df=va,\n",
    "    target_col=TARGET_COL,\n",
    "    drop_cols=drop_cols + spec[\"text_cols\"],  # tabular-only: drop raw text\n",
    "    timeout=600,\n",
    "    cpu_limit=4,\n",
    "    params={\"use_algos\": [[\"lgb\"]]},  # simple, strong baseline\n",
    "    verbose=2,\n",
    ")\n",
    "score_a = log_loss(y_va, res_a.valid_pred, labels=labels)\n",
    "print(\"LAMA Config A logloss:\", score_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:16] Stdout logging level is INFO2.\n",
      "[14:11:16] Task: multiclass\n",
      "\n",
      "[14:11:16] Start automl preset with listed constraints:\n",
      "[14:11:16] - time: 1800.00 seconds\n",
      "[14:11:16] - CPU: 4 cores\n",
      "[14:11:16] - memory: 16 GB\n",
      "\n",
      "[14:11:16] \u001b[1mTrain data shape: (39481, 34)\u001b[0m\n",
      "\n",
      "[14:11:17] Layer \u001b[1m1\u001b[0m train process start. Time left 1799.07 secs\n",
      "[14:11:19] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[14:11:19] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
     ]
    }
   ],
   "source": [
    "# --- Config B: TabularAutoML (stronger: more time + more algos) ---\n",
    "res_b = fit_lama_tabular(\n",
    "    train_df=tr,\n",
    "    valid_df=va,\n",
    "    target_col=TARGET_COL,\n",
    "    drop_cols=drop_cols + spec[\"text_cols\"],\n",
    "    timeout=1800,\n",
    "    cpu_limit=4,\n",
    "    params={\"use_algos\": [[\"lgb\", \"linear_l2\"]]},\n",
    "    verbose=2,\n",
    ")\n",
    "score_b = log_loss(y_va, res_b.valid_pred, labels=labels)\n",
    "print(\"LAMA Config B logloss:\", score_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565de9d",
   "metadata": {},
   "source": [
    "## LAMA with text (TabularNLPAutoML)\n",
    "\n",
    "This may require external model downloads depending on `text_params/autonlp_params`.\n",
    "If you run in a restricted environment, you can skip this section.\n",
    "\n",
    "(If it runs, it's a great second baseline to mention in the report.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NLP = False  # set True if you run on Kaggle / environment with required NLP deps & downloads\n",
    "\n",
    "if RUN_NLP:\n",
    "    res_nlp = fit_lama_tabular_nlp(\n",
    "        train_df=tr,\n",
    "        valid_df=va,\n",
    "        target_col=TARGET_COL,\n",
    "        drop_cols=drop_cols,\n",
    "        text_cols=spec[\"text_cols\"],\n",
    "        timeout=1800,\n",
    "        cpu_limit=4,\n",
    "        params={\"use_algos\": [[\"linear_l2\", \"lgb\"]]},\n",
    "        text_params={\"lang\": \"en\"},\n",
    "        tfidf_params={\"ngram_range\": (1, 2), \"max_features\": 80000},\n",
    "        autonlp_params=None,  # keep TF-IDF only\n",
    "        verbose=2,\n",
    "    )\n",
    "    score_nlp = log_loss(y_va, res_nlp.valid_pred, labels=labels)\n",
    "    print(\"LAMA NLP logloss:\", score_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85823115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n",
    "results = pd.DataFrame(\n",
    "    [\n",
    "        {\"config\": \"TabularAutoML A (lgb, 600s)\", \"logloss\": score_a},\n",
    "        {\"config\": \"TabularAutoML B (lgb+linear, 1800s)\", \"logloss\": score_b},\n",
    "    ]\n",
    ").sort_values(\"logloss\")\n",
    "display(results)\n",
    "\n",
    "ax = results.set_index(\"config\")[\"logloss\"].plot(kind=\"barh\", figsize=(8,3))\n",
    "ax.set_title(\"LAMA baseline comparison (lower is better)\")\n",
    "ax.set_xlabel(\"logloss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09bb82",
   "metadata": {},
   "source": [
    "## Save best LAMA model + create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be022b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = res_a.model if score_a <= score_b else res_b.model\n",
    "best_name = \"lama_a\" if score_a <= score_b else \"lama_b\"\n",
    "\n",
    "# Fit on full train and predict test\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "\n",
    "roles = {\"target\": TARGET_COL, \"drop\": drop_cols + spec[\"text_cols\"]}\n",
    "task = Task(\"multiclass\")\n",
    "\n",
    "automl_full = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=1800,\n",
    "    cpu_limit=4,\n",
    "    general_params={\"use_algos\": [[\"lgb\", \"linear_l2\"]]},\n",
    ")\n",
    "_ = automl_full.fit_predict(train_df, roles=roles, verbose=2)\n",
    "test_pred = automl_full.predict(test_df).data\n",
    "\n",
    "sub = pd.DataFrame({ID_COL: test_df[ID_COL].values})\n",
    "sub[labels] = test_pred\n",
    "\n",
    "out_path = paths.submissions / f\"submission_{best_name}.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(\"Saved submission:\", out_path)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78f965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
