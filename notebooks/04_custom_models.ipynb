{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87dd63dc",
   "metadata": {},
   "source": [
    "# 04 — Custom models (WITHOUT LAMA)\n",
    "\n",
    "Goal: beat the best LAMA baseline.\n",
    "\n",
    "We implement **multiple pipelines**:\n",
    "1) TF‑IDF (text) + OHE (cats) + numeric → **LogReg**\n",
    "2) Target Encoding (cats) + numeric → **LightGBM**\n",
    "3) CatBoost on tabular → **CatBoostClassifier**\n",
    "\n",
    "Plus: **Optuna tuning** for LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from src.config import Paths, TARGET_COL, ID_COL, SEED\n",
    "from src.models.cv import stratified_cv_predict_proba\n",
    "from src.models.custom import (\n",
    "    make_tfidf_linear_pipeline,\n",
    "    fit_predict_proba_sklearn,\n",
    "    make_lgbm_target_enc_pipeline,\n",
    "    fit_predict_proba_lgbm_target_enc,\n",
    "    make_catboost_model,\n",
    "    fit_predict_proba_catboost,\n",
    ")\n",
    "from src.utils.seed import set_global_seed\n",
    "\n",
    "set_global_seed(SEED)\n",
    "paths = Paths()\n",
    "\n",
    "df = pd.read_parquet(paths.data_processed/\"model_table.parquet\")\n",
    "spec = json.loads((paths.data_processed/\"feature_spec.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "train_df = df[df[TARGET_COL].notna()].copy()\n",
    "test_df  = df[df[TARGET_COL].isna()].copy()\n",
    "\n",
    "labels = [\"high\",\"medium\",\"low\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e55e7",
   "metadata": {},
   "source": [
    "## Pipeline 1: TF‑IDF + Logistic Regression (strong baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d102ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"] + spec[\"text_cols\"]].copy()\n",
    "y = train_df[TARGET_COL].copy()\n",
    "\n",
    "tfidf_pipe = make_tfidf_linear_pipeline(\n",
    "    numeric_cols=spec[\"numeric_cols\"],\n",
    "    categorical_cols=spec[\"categorical_cols\"],\n",
    "    text_cols=spec[\"text_cols\"],\n",
    "    max_features=70000,\n",
    ")\n",
    "\n",
    "def fit_pred_fn(X_tr, y_tr, X_va):\n",
    "    return fit_predict_proba_sklearn(tfidf_pipe, X_tr, y_tr, X_va)\n",
    "\n",
    "res = stratified_cv_predict_proba(fit_pred_fn, X, y, labels=labels, n_splits=5, seed=SEED)\n",
    "print(\"Mean CV logloss:\", res.mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8b004",
   "metadata": {},
   "source": [
    "## Pipeline 2: Target Encoding + LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab = train_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"]].copy()\n",
    "y_tab = train_df[TARGET_COL].copy()\n",
    "\n",
    "enc, lgbm = make_lgbm_target_enc_pipeline(\n",
    "    numeric_cols=spec[\"numeric_cols\"],\n",
    "    categorical_cols=spec[\"categorical_cols\"],\n",
    "    params={\"n_estimators\": 2500},\n",
    ")\n",
    "\n",
    "def fit_pred_fn2(X_tr, y_tr, X_va):\n",
    "    return fit_predict_proba_lgbm_target_enc(enc, lgbm, X_tr, y_tr, X_va)\n",
    "\n",
    "res2 = stratified_cv_predict_proba(fit_pred_fn2, X_tab, y_tab, labels=labels, n_splits=5, seed=SEED)\n",
    "print(\"Mean CV logloss:\", res2.mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946dcb3",
   "metadata": {},
   "source": [
    "## Pipeline 3: CatBoost (tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcddbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cb = train_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"]].copy()\n",
    "y_cb = train_df[TARGET_COL].copy()\n",
    "\n",
    "cb_model = make_catboost_model(cat_cols=spec[\"categorical_cols\"], params={\"iterations\": 2000})\n",
    "\n",
    "def fit_pred_fn3(X_tr, y_tr, X_va):\n",
    "    m = make_catboost_model(cat_cols=spec[\"categorical_cols\"], params={\"iterations\": 2000})\n",
    "    return fit_predict_proba_catboost(m, X_tr, y_tr, X_va, cat_cols=spec[\"categorical_cols\"])\n",
    "\n",
    "res3 = stratified_cv_predict_proba(fit_pred_fn3, X_cb, y_cb, labels=labels, n_splits=5, seed=SEED)\n",
    "print(\"Mean CV logloss:\", res3.mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c57226",
   "metadata": {},
   "source": [
    "## Compare pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comp = pd.DataFrame([\n",
    "    {\"pipeline\": \"TF‑IDF + LogisticRegression\", \"logloss\": res.mean_score},\n",
    "    {\"pipeline\": \"TargetEnc + LightGBM\", \"logloss\": res2.mean_score},\n",
    "    {\"pipeline\": \"CatBoost (tabular)\", \"logloss\": res3.mean_score},\n",
    "]).sort_values(\"logloss\")\n",
    "\n",
    "display(comp)\n",
    "\n",
    "ax = comp.set_index(\"pipeline\")[\"logloss\"].plot(kind=\"barh\", figsize=(8,3))\n",
    "ax.set_title(\"Custom pipelines (lower is better)\")\n",
    "ax.set_xlabel(\"CV logloss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2374d",
   "metadata": {},
   "source": [
    "## Optuna tuning example (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7061e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.08, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 32, 256),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"n_estimators\": 3000,\n",
    "    }\n",
    "\n",
    "    enc, model = make_lgbm_target_enc_pipeline(\n",
    "        numeric_cols=spec[\"numeric_cols\"],\n",
    "        categorical_cols=spec[\"categorical_cols\"],\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in skf.split(X_tab, y_tab):\n",
    "        X_tr, X_va = X_tab.iloc[tr_idx], X_tab.iloc[va_idx]\n",
    "        y_tr, y_va = y_tab.iloc[tr_idx], y_tab.iloc[va_idx]\n",
    "        proba = fit_predict_proba_lgbm_target_enc(enc, model, X_tr, y_tr, X_va)\n",
    "        scores.append(log_loss(y_va, proba, labels=labels))\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best value :\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb92e1",
   "metadata": {},
   "source": [
    "## Train best custom pipeline on full train and create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best pipeline from comp table\n",
    "best = comp.iloc[0][\"pipeline\"]\n",
    "print(\"Best by CV:\", best)\n",
    "\n",
    "if best == \"TF‑IDF + LogisticRegression\":\n",
    "    pipe = make_tfidf_linear_pipeline(spec[\"numeric_cols\"], spec[\"categorical_cols\"], spec[\"text_cols\"], max_features=70000)\n",
    "    X_full = train_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"] + spec[\"text_cols\"]]\n",
    "    y_full = train_df[TARGET_COL]\n",
    "    pipe.fit(X_full, y_full)\n",
    "    X_test = test_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"] + spec[\"text_cols\"]]\n",
    "    pred = pipe.predict_proba(X_test)\n",
    "\n",
    "elif best == \"TargetEnc + LightGBM\":\n",
    "    best_params = getattr(study, \"best_params\", {})\n",
    "    enc, model = make_lgbm_target_enc_pipeline(spec[\"numeric_cols\"], spec[\"categorical_cols\"], params={**best_params, \"n_estimators\": 4000})\n",
    "    X_full = train_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"]]\n",
    "    y_full = train_df[TARGET_COL]\n",
    "    enc.fit(X_full.fillna(0), y_full)\n",
    "    X_full_enc = enc.transform(X_full.fillna(0))\n",
    "    model.fit(X_full_enc, y_full)\n",
    "    X_test = test_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"]]\n",
    "    pred = model.predict_proba(enc.transform(X_test.fillna(0)))\n",
    "\n",
    "else:\n",
    "    model = make_catboost_model(cat_cols=spec[\"categorical_cols\"], params={\"iterations\": 2500})\n",
    "    X_full = train_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"]]\n",
    "    y_full = train_df[TARGET_COL]\n",
    "    cat_idx = [X_full.columns.get_loc(c) for c in spec[\"categorical_cols\"]]\n",
    "    model.fit(X_full, y_full, cat_features=cat_idx)\n",
    "    X_test = test_df[spec[\"numeric_cols\"] + spec[\"categorical_cols\"]]\n",
    "    pred = model.predict_proba(X_test)\n",
    "\n",
    "sub = pd.DataFrame({ID_COL: test_df[ID_COL].values})\n",
    "sub[labels] = pred\n",
    "\n",
    "out_path = paths.submissions / \"submission_custom_best.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}